{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60963994-25f6-449e-b03d-8f089849ced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tripduration', 'starttime', 'stoptime', 'start station id',\n",
      "       'start station name', 'start station latitude',\n",
      "       'start station longitude', 'end station id', 'end station name',\n",
      "       'end station latitude', 'end station longitude', 'bikeid', 'usertype',\n",
      "       'birth year', 'gender'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "\n",
    "# 获取所有 CSV 文件的路径\n",
    "file_paths = glob.glob('../data/2019-citibike-tripdata/10_October/201910-citibike-tripdata_*.csv')\n",
    "\n",
    "# 读取并合并所有 CSV 文件\n",
    "dataframes = [pd.read_csv(file) for file in file_paths]\n",
    "citibike_df = pd.concat(dataframes, ignore_index=True)\n",
    "print(citibike_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba1a342-f4a6-4e16-99bd-596c2b602343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start station id             start station name  ride start count  \\\n",
      "0              72.0               W 52 St & 11 Ave            3518.0   \n",
      "1              79.0       Franklin St & W Broadway            2703.0   \n",
      "2              82.0         St James Pl & Pearl St            1460.0   \n",
      "3              83.0  Atlantic Ave & Fort Greene Pl            2016.0   \n",
      "4             116.0                W 17 St & 8 Ave            7721.0   \n",
      "\n",
      "   end station id               end station name  ride end count  \\\n",
      "0              72               W 52 St & 11 Ave            3421   \n",
      "1              79       Franklin St & W Broadway            2746   \n",
      "2              82         St James Pl & Pearl St            1450   \n",
      "3              83  Atlantic Ave & Fort Greene Pl            2071   \n",
      "4             116                W 17 St & 8 Ave            7839   \n",
      "\n",
      "   ride activity  \n",
      "0           6939  \n",
      "1           5449  \n",
      "2           2910  \n",
      "3           4087  \n",
      "4          15560  \n"
     ]
    }
   ],
   "source": [
    "# 计算每个站点的开始和结束骑行次数\n",
    "start_station_counts = citibike_df.groupby(['start station id', 'start station name']).size().reset_index(name='ride start count')\n",
    "end_station_counts = citibike_df.groupby(['end station id', 'end station name']).size().reset_index(name='ride end count')\n",
    "\n",
    "# 合并开始和结束骑行次数\n",
    "station_activity = pd.merge(start_station_counts, end_station_counts,\n",
    "                            left_on='start station id', right_on='end station id',\n",
    "                            how='outer').fillna(0)\n",
    "\n",
    "# 计算总骑行活动\n",
    "station_activity['ride activity'] = (station_activity['ride start count'] + station_activity['ride end count']).astype(int)\n",
    "print(station_activity.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d86648-34e4-4cde-9a7d-f42a1f19ffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique start stations: 838\n",
      "Unique end stations: 848\n",
      "Total unique stations: 849\n"
     ]
    }
   ],
   "source": [
    "# 统计唯一的起始站点和结束站点的个数\n",
    "unique_start_stations = station_activity['start station id'].nunique()\n",
    "unique_end_stations = station_activity['end station id'].nunique()\n",
    "\n",
    "# 打印结果\n",
    "print(f\"Unique start stations: {unique_start_stations}\")\n",
    "print(f\"Unique end stations: {unique_end_stations}\")\n",
    "\n",
    "# 或者，如果你想统计所有站点的总数（不考虑起始或结束），可以合并后去重\n",
    "all_stations = pd.concat([station_activity['start station id'], station_activity['end station id']]).nunique()\n",
    "print(f\"Total unique stations: {all_stations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daeaa6bf-fd3f-4f45-8958-c7b00312fd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 读取 Shapefile\n",
    "shapefile_path = \"../data/nyc2020_census/nyct2020.shp\"\n",
    "census_gdf = gpd.read_file(shapefile_path)\n",
    "census_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d778790d-e157-4542-8507-8ae5c2aedef1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_station_gdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 确保普查区和站点的 CRS 一致\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m census_gdf \u001b[38;5;241m=\u001b[39m census_gdf\u001b[38;5;241m.\u001b[39mto_crs(\u001b[43mstart_station_gdf\u001b[49m\u001b[38;5;241m.\u001b[39mcrs)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 执行空间连接，找到每个起始站点所属的普查区\u001b[39;00m\n\u001b[1;32m      5\u001b[0m start_stations_in_census \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39msjoin(start_station_gdf, census_gdf, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m, op\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_station_gdf' is not defined"
     ]
    }
   ],
   "source": [
    "# 确保普查区和站点的 CRS 一致\n",
    "census_gdf = census_gdf.to_crs(start_station_gdf.crs)\n",
    "\n",
    "# 执行空间连接，找到每个起始站点所属的普查区\n",
    "start_stations_in_census = gpd.sjoin(start_station_gdf, census_gdf, how=\"inner\", op=\"within\")\n",
    "\n",
    "# 执行空间连接，找到每个终点站点所属的普查区\n",
    "end_stations_in_census = gpd.sjoin(end_station_gdf, census_gdf, how=\"inner\", op=\"within\")\n",
    "\n",
    "# 计算每个站点的开始和结束骑行次数\n",
    "start_station_counts = citibike_df.groupby(['start station id', 'start station name']).size().reset_index(name='ride start count')\n",
    "end_station_counts = citibike_df.groupby(['end station id', 'end station name']).size().reset_index(name='ride end count')\n",
    "\n",
    "# 合并开始和结束骑行次数\n",
    "station_activity = pd.merge(start_station_counts, end_station_counts,\n",
    "                            left_on='start station id', right_on='end station id',\n",
    "                            how='outer').fillna(0)\n",
    "\n",
    "# 计算总骑行活动\n",
    "station_activity['ride activity'] = (station_activity['ride start count'] + station_activity['ride end count']).astype(int)\n",
    "\n",
    "# 将起始站点的活动与普查区关联，并计算普查区的骑行活动和站点数量\n",
    "start_stations_with_activity = pd.merge(\n",
    "    start_stations_in_census,\n",
    "    station_activity[['start station id', 'ride activity']],\n",
    "    left_on='start station id',\n",
    "    right_on='start station id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "end_stations_with_activity = pd.merge(\n",
    "    end_stations_in_census,\n",
    "    station_activity[['end station id', 'ride activity']],\n",
    "    left_on='end station id',\n",
    "    right_on='end station id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 合并起始站点和终点站点的活动\n",
    "all_stations_with_activity = pd.concat([\n",
    "    start_stations_with_activity[['BoroCT2020', 'start station id', 'ride activity']],\n",
    "    end_stations_with_activity[['BoroCT2020', 'end station id', 'ride activity']]\n",
    "])\n",
    "\n",
    "# 统计每个普查区的站点数量\n",
    "station_count = all_stations_with_activity[['BoroCT2020', 'start station id']].drop_duplicates().groupby('BoroCT2020').size().reset_index(name='station count')\n",
    "\n",
    "# 按普查区汇总骑行活动\n",
    "census_ride_activity = all_stations_with_activity.groupby('BoroCT2020')['ride activity'].sum().reset_index()\n",
    "\n",
    "# 将 shape_area 和 station count 添加到结果中\n",
    "census_ride_activity = pd.merge(\n",
    "    census_ride_activity,\n",
    "    census_gdf[['BoroCT2020', 'Shape_Area']],\n",
    "    left_on='BoroCT2020',\n",
    "    right_on='BoroCT2020',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "census_ride_activity = pd.merge(\n",
    "    census_ride_activity,\n",
    "    station_count,\n",
    "    left_on='BoroCT2020',\n",
    "    right_on='BoroCT2020',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 输出结果\n",
    "print(census_ride_activity.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7241f116-bc68-45da-b377-770ebbdb1ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year GeoType Borough        GeoID  BCT2020   Pop1  Male P  FemP PopU5  \\\n",
      "0  2020  CT2020   Bronx  36005000100  2000100  3,772    94.4   5.6     3   \n",
      "1  2020  CT2020   Bronx  36005000200  2000200  4,779    47.7  52.3   234   \n",
      "2  2020  CT2020   Bronx  36005000400  2000400  6,272    47.3  52.7   275   \n",
      "3  2020  CT2020   Bronx  36005001600  2001600  5,795    43.4  56.6   240   \n",
      "4  2020  CT2020   Bronx  36005001901  2001901  2,292    50.4  49.6   158   \n",
      "\n",
      "  Pop5t9  ... Pop80t84 Pop85pl MdAge PopU18 Pop65pl GQClgHsg    Fam  HUnits  \\\n",
      "0      1  ...        6       1  32.8     12      47        0      0       1   \n",
      "1    273  ...       61      96  37.2  1,065     599        0  1,133   1,594   \n",
      "2    374  ...       69      64  38.5  1,337     770        0  1,606   2,200   \n",
      "3    366  ...      131     143  40.2  1,251     986        0  1,380   2,129   \n",
      "4    152  ...        9       6  32.7    567      79        0    501   1,049   \n",
      "\n",
      "   OcHU_1P  AvgHHSz  \n",
      "0      NaN      NaN  \n",
      "1     95.2     3.15  \n",
      "2     95.9     2.97  \n",
      "3     95.9     2.73  \n",
      "4     94.2     2.29  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "Year          int64\n",
      "GeoType      object\n",
      "Borough      object\n",
      "GeoID         int64\n",
      "BCT2020      object\n",
      "Pop1          int64\n",
      "Male P      float64\n",
      "FemP        float64\n",
      "PopU5        object\n",
      "Pop5t9       object\n",
      "Pop10t14     object\n",
      "Pop15t19     object\n",
      "Pop20t24     object\n",
      "Pop25t29     object\n",
      "Pop30t34     object\n",
      "Pop35t39     object\n",
      "Pop40t44      int64\n",
      "Pop45t49      int64\n",
      "Pop50t54      int64\n",
      "Pop55t59      int64\n",
      "Pop60t64      int64\n",
      "Pop65t69      int64\n",
      "Pop70t74      int64\n",
      "Pop75t79      int64\n",
      "Pop80t84      int64\n",
      "Pop85pl       int64\n",
      "MdAge       float64\n",
      "PopU18       object\n",
      "Pop65pl      object\n",
      "GQClgHsg     object\n",
      "Fam          object\n",
      "HUnits       object\n",
      "OcHU_1P     float64\n",
      "AvgHHSz     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 加载人口统计数据\n",
    "population_data = pd.read_csv(\"../data/nyc_censusdata_2020.csv\")\n",
    "\n",
    "# 检查数据加载情况\n",
    "print(population_data.head())\n",
    "# 去除逗号并将人口列转换为整数\n",
    "population_data['Pop1'] = population_data['Pop1'].str.replace(',', '').astype(int)\n",
    "# 将 BCT2020 字段转换为字符串类型\n",
    "population_data['BCT2020'] = population_data['BCT2020'].astype(str)\n",
    "# 检查数据格式\n",
    "print(population_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15f34b56-8bfd-42eb-8a54-79c6cc06fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year GeoType Borough        GeoID  BCT2020  Pop1  Male P  FemP PopU5  \\\n",
      "0  2020  CT2020   Bronx  36005000100  2000100  3772    94.4   5.6     3   \n",
      "1  2020  CT2020   Bronx  36005000200  2000200  4779    47.7  52.3   234   \n",
      "2  2020  CT2020   Bronx  36005000400  2000400  6272    47.3  52.7   275   \n",
      "3  2020  CT2020   Bronx  36005001600  2001600  5795    43.4  56.6   240   \n",
      "4  2020  CT2020   Bronx  36005001901  2001901  2292    50.4  49.6   158   \n",
      "\n",
      "  Pop5t9  ... PopU18 Pop65pl GQClgHsg    Fam HUnits OcHU_1P  AvgHHSz  \\\n",
      "0      1  ...     12      47        0      0      1     NaN      NaN   \n",
      "1    273  ...  1,065     599        0  1,133  1,594    95.2     3.15   \n",
      "2    374  ...  1,337     770        0  1,606  2,200    95.9     2.97   \n",
      "3    366  ...  1,251     986        0  1,380  2,129    95.9     2.73   \n",
      "4    152  ...    567      79        0    501  1,049    94.2     2.29   \n",
      "\n",
      "   ride activity  Shape_Area  station count  \n",
      "0            NaN         NaN            NaN  \n",
      "1            NaN         NaN            NaN  \n",
      "2            NaN         NaN            NaN  \n",
      "3            NaN         NaN            NaN  \n",
      "4            NaN         NaN            NaN  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "census_ride_activity.rename(columns={'BoroCT2020': 'BCT2020'}, inplace=True)\n",
    "census_ride_activity['BCT2020'] = census_ride_activity['BCT2020'].astype(str)\n",
    "\n",
    "# 合并骑行活动数据和人口统计数据\n",
    "merged_data = pd.merge(population_data, census_ride_activity, on='BCT2020', how='left')\n",
    "# 检查合并后的数据\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9177456f-b2f1-4616-af5c-c571090a231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv(\"merged_census_ride_activity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f908e28-0868-449d-8bda-8f0812686240",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = merged_data.dropna(subset=['ride activity','Shape_Area'])\n",
    "filtered_data.to_csv(\"filtered_data_ride_activity.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4396419-1071-4059-a9e5-0aaf2c77869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 'linear_model_data.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/cy038g3n0b76wc7182ktv28r0000gn/T/ipykernel_5349/1438945672.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_data.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 创建副本以避免 SettingWithCopyWarning\n",
    "filtered_data = filtered_data.copy()\n",
    "\n",
    "# 将可能包含字符串的数值列转换为数字类型\n",
    "columns_to_convert = [\n",
    "    'Pop15t19', 'Pop20t24', 'Pop25t29', 'Pop30t34', 'Pop35t39', 'Pop40t44',\n",
    "    'Pop45t49', 'Pop50t54', 'Pop55t59', 'Pop60t64', 'PopU18', 'Pop65pl',\n",
    "    'HUnits', 'Fam', 'AvgHHSz', 'GQClgHsg', 'ride activity', 'Shape_Area'\n",
    "]\n",
    "\n",
    "# 去除逗号并转换为数字\n",
    "for col in columns_to_convert:\n",
    "    filtered_data[col] = (\n",
    "        filtered_data[col]\n",
    "        .replace({',': ''}, regex=True)  # 去除逗号\n",
    "        .astype(float)  # 转换为浮点数\n",
    "    )\n",
    "\n",
    "\n",
    "# 计算 pop19to64\n",
    "filtered_data['pop19to64'] = (\n",
    "    filtered_data['Pop15t19'] + filtered_data['Pop20t24'] + filtered_data['Pop25t29'] +\n",
    "    filtered_data['Pop30t34'] + filtered_data['Pop35t39'] + filtered_data['Pop40t44'] +\n",
    "    filtered_data['Pop45t49'] + filtered_data['Pop50t54'] + filtered_data['Pop55t59'] +\n",
    "    filtered_data['Pop60t64']\n",
    ")\n",
    "\n",
    "# 将 station count 列重命名为 num_stations（如果存在）\n",
    "filtered_data.rename(columns={'station count': 'num_stations'}, inplace=True)\n",
    "\n",
    "# 准备自变量和因变量\n",
    "variables = [\n",
    "    'PopU18', 'pop19to64', 'Pop65pl', 'HUnits', 'Fam',\n",
    "    'AvgHHSz', 'GQClgHsg', 'Shape_Area', 'num_stations'\n",
    "]\n",
    "target = 'ride activity'\n",
    "\n",
    "# 创建一个新的 DataFrame，只包含自变量和因变量\n",
    "final_data = filtered_data[variables + [target]]\n",
    "final_data.fillna(0, inplace=True)\n",
    "# 保存到 CSV 文件\n",
    "final_data.to_csv('linear_model_data.csv', index=False)\n",
    "\n",
    "print(\"数据已保存到 'linear_model_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3228f6ec-e975-4bfe-975f-7edf87d944eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "截距项: -20143375.746277392\n",
      "回归系数: [ 8.65145434e+04 -3.59147675e+04  8.53407467e+03  1.21548420e+05\n",
      " -2.60700830e+05 -2.59702870e+07  1.21212890e+05 -3.68619069e+00\n",
      "  5.92091401e+07]\n",
      "R²: 0.33814776659456725\n",
      "均方误差 (MSE): 2.3408791326254436e+16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 自变量和因变量\n",
    "X = final_data[variables]  # 自变量\n",
    "y = final_data[target]     # 因变量\n",
    "\n",
    "# 初始化模型\n",
    "model = LinearRegression()\n",
    "\n",
    "# 拟合模型\n",
    "model.fit(X, y)\n",
    "\n",
    "# 输出模型系数和截距\n",
    "print(\"截距项:\", model.intercept_)\n",
    "print(\"回归系数:\", model.coef_)\n",
    "\n",
    "# 预测\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# 计算 R² 和均方误差\n",
    "print(\"R²:\", r2_score(y, y_pred))\n",
    "print(\"均方误差 (MSE):\", mean_squared_error(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8cd3cc4-95d7-4045-bdb2-2a6aa11ed8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PopU18               86514.54338162004\n",
      "pop19to64            -35914.76754649207\n",
      "Pop65pl              8534.074670093802\n",
      "HUnits               121548.41953447071\n",
      "Fam                  -260700.83040967246\n",
      "AvgHHSz              -25970286.95563022\n",
      "GQClgHsg             121212.8895676617\n",
      "Shape_Area           -3.6861906888816063\n",
      "num_stations         59209140.07654531\n"
     ]
    }
   ],
   "source": [
    "for idx, col in enumerate(model.coef_):\n",
    "    print(variables[idx].ljust(20), col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e04ee-a2e4-4326-8277-71722ca56d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

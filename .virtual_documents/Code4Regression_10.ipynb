library(sf)
library(tmap)
library(tmaptools)
library(dplyr)
library(lubridate)
library(ggplot2)
library(gstat)
library(sp)


# Read the census shapefile
census <- st_read(dsn="./data/nyc2020_census/nyct2020.shp", layer="nyct2020")

# Load the population csv data
population <- read.csv("./data/nyc_censusdata_2020.csv")
population$BCT2020 <- as.character(population$BCT2020)

# Join population data to census data
census_joined <- census %>%
  left_join(population, by= c("BoroCT2020"="BCT2020"))

# Plot census polygons
plot(census_joined["CT2020"])

# Load Citibike data
citibike_1 <- read.csv("./data/2019-citibike-tripdata/10_October/201910-citibike-tripdata_1.csv")
citibike_2 <- read.csv("./data/2019-citibike-tripdata/10_October/201910-citibike-tripdata_2.csv")
citibike_3 <- read.csv("./data/2019-citibike-tripdata/10_October/201910-citibike-tripdata_3.csv")
citibike_oct <- bind_rows(citibike_1, citibike_2, citibike_3)


# Convert starttime and stoptime into DateTime format
citibike_oct$starttime <- ymd_hms(citibike_oct$starttime)
citibike_oct$stoptime <- ymd_hms(citibike_oct$stoptime)

# Cleaning up for weekday/weekend and hour information
citibike_oct <- citibike_oct %>%
  mutate(
    # Weekday or weekend
    is_weekend = ifelse(wday(starttime) %in% c(1,7), TRUE, FALSE),
    # Start time hour
    start_hour = hour(starttime)
  )


# Create the station dataset with attributes on station id/lat/long, ride counts, user counts and time-based counts
start_station_oct <- citibike_oct %>%
  # Group by start.station and user type
  group_by(start.station.id, start.station.latitude, start.station.longitude) %>%
  summarise(
    ride_start_count = n(),
    usertype_subscriber_count = sum(usertype == "Subscriber"),
    usertype_customer_count = sum(usertype == "Customer"),
    
    # Weekday counts for time intervals AM/PM Peak/Off-Peak - ref Liu et al
    ride_start_weekday_7_10 = sum(!is_weekend & start_hour>=7 & start_hour<10),
    ride_start_weekday_10_17 = sum(!is_weekend & start_hour>=10 & start_hour<17),
    ride_start_weekday_17_0 = sum(!is_weekend & start_hour>=17 & start_hour<24),
    ride_start_weekday_0_7 = sum(!is_weekend & start_hour>=0 & start_hour<7),
    
    # Weekend counts for leisure/others - ref Liu et al
    ride_start_weekend_10_0 = sum(is_weekend & start_hour>=10 & start_hour<24),
    ride_start_weekend_0_10 = sum(is_weekend & start_hour>=0 & start_hour<10)
  ) %>%
  rename(
    station_id = start.station.id,
    station_latitude = start.station.latitude,
    station_longitude = start.station.longitude
  )

# Calculate end station counts  
end_station_oct <- citibike_oct %>%
  group_by(end.station.id, end.station.latitude, end.station.longitude) %>%
  summarise(
    ride_end_count = n()
  ) %>%
  rename(
    station_id = end.station.id,
    station_latitude = end.station.latitude,
    station_longitude = end.station.longitude
  )

# Combine start and end to return ride activity by station
station_oct <- full_join(start_station_oct, end_station_oct,
                          by= c("station_id", "station_latitude", "station_longitude")) %>%
  # Deal with NA values
  mutate(
    ride_start_count = ifelse(is.na(ride_start_count), 0, ride_start_count),
    ride_end_count = ifelse(is.na(ride_end_count), 0, ride_end_count),
    ride_activity = ride_start_count + ride_end_count
  )

# Add median trip duration for start stations
start_station_duration <- citibike_oct %>%
  group_by(start.station.id) %>%
  summarise(median_trip_duration_start = median(tripduration, na.rm=TRUE)) %>%
  rename(station_id = start.station.id)

# Add median trip duration for end stations
end_station_duration <- citibike_oct %>%
  group_by(end.station.id) %>%
  summarise(median_trip_duration_end = median(tripduration, na.rm=TRUE)) %>%
  rename(station_id = end.station.id)

# Merge median trip duration with station_july
station_oct <- station_oct %>%
  left_join(start_station_duration, by= "station_id") %>%
  left_join(end_station_duration, by= "station_id")


# Convert cleaned July dataset into sf object
station_oct_sf <- station_oct %>%
  st_as_sf(coords = c("station_longitude", "station_latitude"), crs=4326, remove=FALSE)

# Plot map of points
tm_shape(station_oct_sf) +
  tm_bubbles(size=0.1, col="ride_activity", palette="YlOrRd") +
  tm_layout(main.title = "Citibike oct 2019",
            main.title.size=1.5, frame=FALSE, legend.position = c("left", "top"))


# Convert Census polygon crs4269 to crs4329
census_joined <- st_transform(census_joined, crs=st_crs(station_oct_sf))

# Plot interim data
tm_shape(census) +
  tm_borders() +
  tm_shape(station_oct_sf) +
  tm_bubbles(size=0.1, col="ride_activity", palette="YlOrRd") + 
  tm_layout(main.title = "Citibike oct 2019 and Census Polygons",
            main.title.size=1, frame=FALSE, legend.position= c("left", "top"))


# Creating an aggregated station dataset at census tract level
station_oct_nyc <- station_oct_sf %>%
  # Left join to remove stations outside NYC (do not have census tract)
  st_join(census_joined, join= st_within, left=FALSE)
ct_station_oct <- station_oct_nyc %>%
  group_by(BoroCT2020) %>%
  summarise(
    num_stations = n(),
    total_ride_start_count = sum(ride_start_count, na.rm=TRUE),
    total_ride_end_count = sum(ride_end_count, na.rm=TRUE),
    total_ride_activity = sum(ride_activity, na.rm=TRUE),
    median_trip_duration_start = median(median_trip_duration_start, na.rm=TRUE),
    median_trip_duration_end = median(median_trip_duration_end, na.rm=TRUE),
    usertype_subscriber_count = sum(usertype_subscriber_count, na.rm=TRUE),
    usertype_customer_count = sum(usertype_customer_count, na.rm=TRUE),
    # Adding in the time factor
    weekday_7_10 = sum(ride_start_weekday_7_10, na.rm=TRUE),
    weekday_10_17 = sum(ride_start_weekday_10_17, na.rm=TRUE),
    weekday_17_0 = sum(ride_start_weekday_17_0, na.rm=TRUE),
    weekday_0_7 = sum(ride_start_weekday_0_7, na.rm=TRUE),
    weekend_10_0 = sum(ride_start_weekend_10_0, na.rm=TRUE),
    weekend_0_10 = sum(ride_start_weekend_0_10, na.rm=TRUE)
  )

# Converting to df to allow for inner join and drop column for polygons without Citibike docks
ct_station_oct_df <- as.data.frame(ct_station_oct)
agg_citibike_oct <- census_joined %>%
  inner_join(ct_station_oct_df, by= "BoroCT2020")

# colnames(agg_citibike_oct)
# agg_citibike_oct <- agg_citibike_oct_copy

# List of columns to convert from character to integer
columns_to_convert <- c("Pop1", "PopU5", "Pop5t9", "Pop10t14", "Pop15t19", "Pop20t24", "Pop25t29", "Pop30t34", "Pop35t39", "PopU18", "Pop65pl", "GQClgHsg", "Fam", "HUnits")
# Note: chr values with comma (e.g. "3,512") automatically converts to NA -- therefore need to remove the comma
agg_citibike_oct[columns_to_convert] <- lapply(agg_citibike_oct[columns_to_convert], function(x) {
  x <- gsub(",", "", x)             # Remove commas
  x <- as.numeric(x)                # Convert to numeric
  x[is.na(x)] <- 0                  # Replace NAs with 0
  return(x)
})


# Replace NA with 0 for all numeric and integer columns
agg_citibike_oct[sapply(agg_citibike_oct, is.numeric)] <- 
  lapply(agg_citibike_oct[sapply(agg_citibike_oct, is.numeric)], function(x) {
    x[is.na(x)] <- 0
    return(x)
  })


# Verify if there are any remaining NAs
sum(is.na(agg_citibike_oct))


# Create a new column 'Pop19t64' as Pop1 - PopU18 - Pop65pl
agg_citibike_oct$Pop19t64 <- agg_citibike_oct$Pop1 - agg_citibike_oct$PopU18 - agg_citibike_oct$Pop65pl

# Verify the result
head(agg_citibike_oct[, c("Pop1", "PopU18", "Pop65pl", "Pop19t64")])


# Plotting the map with context
tm_shape(census_joined)+
  tm_borders(col= "white")+
  tm_fill(col= "lightgrey")+
  tm_shape(agg_citibike_oct)+
  tm_polygons(col= "total_ride_start_count",
              style= "quantile",
              palette= "YlOrRd",
              title= "Total Ride Start Count")+
  tm_layout(title= "Citibike Ride Activity by Census Tract (oct 2019)",
            title.position= c("left", "top"),
            legend.position= c("left", "top"),
            legend.outside= FALSE,
            frame= FALSE)


# Plotting the map with context
tm_shape(census_joined)+
  tm_borders(col= "white")+
  tm_fill(col= "lightgrey")+
  tm_shape(agg_citibike_oct)+
  tm_polygons(col= "median_trip_duration_start",
              style= "quantile",
              palette= "RdPu",
              title= "Median Trip Duration")+
  tm_layout(title= "Citibike Ride Activity by Census Tract (oct 2019)",
            title.position= c("left", "top"),
            legend.position= c("left", "top"),
            legend.outside= FALSE,
            frame= FALSE)


# Plot histogram
ggplot(data=agg_citibike_oct, aes(total_ride_activity)) + geom_histogram()


library(spdep)
library(knitr)
nb <- poly2nb(agg_citibike_oct)


W <- nb2mat(nb, style='W', zero.policy = TRUE)
colnames(W) <- rownames(W)

# Creating a weights list
Wl <- nb2listw(nb, zero.policy = TRUE)
moran(agg_citibike_oct$total_ride_start_count, Wl, n=length(Wl$neighbours), S0=Szero(Wl))


moran.test(agg_citibike_oct$total_ride_start_count, Wl)


moran.mc(agg_citibike_oct$total_ride_start_count, Wl, nsim=999)


# Moran Scatterplot
moran.plot(agg_citibike_oct$total_ride_start_count, Wl, xlab='Total Ride Start Count', ylab='Spatially Lagged Ride Start Count', labels=agg_citibike_oct$NTAName)


NbrL <- dnearneigh(st_centroid(agg_citibike_oct), 0, 1.6)


# Creating a list of neighbours not including self
D <- nb2listw(NbrL, style='B')
# Creating a list of neighbours, but include self
D_star <- nb2listw(include.self(NbrL), style='B')

G <- globalG.test(agg_citibike_oct$total_ride_start_count, D)
G <- globalG.test(agg_citibike_oct$total_ride_start_count, D_star)

# Check if there are any isolated observations (no neighbors) by returning the length (number of neighbours) for each polygon
sapply(NbrL, length)


Gi <- localG(agg_citibike_oct$total_ride_start_count, D)
agg_citibike_oct$Gi <- Gi
Gi_star <- localG(agg_citibike_oct$total_ride_start_count, D_star)
agg_citibike_oct$Gi_star <- Gi_star

tm_shape(agg_citibike_oct) + tm_polygons(col='Gi', palette='-RdBu', style='quantile')


tm_shape(agg_citibike_oct) + tm_polygons(col='Gi_star', palette='-RdBu', style='quantile')


# Local Moran's I
Ii <- localmoran(agg_citibike_oct$total_ride_start_count, Wl)
agg_citibike_oct$Ii <- Ii[,'Ii']
tm_shape(agg_citibike_oct) + tm_polygons(col='Ii', palette='-RdBu', style='quantile')


# Adjusting the p-value
agg_citibike_oct$Iip_unadjusted <- Ii[,'Pr(z != E(Ii))']
agg_citibike_oct$Ii_un_sig <- 'nonsignificant'
agg_citibike_oct$Ii_un_sig[which(agg_citibike_oct$Iip_unadjusted < 0.05)] <- 'significant'
tm_shape(agg_citibike_oct) + tm_polygons(col='Ii_un_sig', palette='-RdBu')


# Adjusting with the Bonferroni method
agg_citibike_oct$Iip_adjusted <- p.adjust(agg_citibike_oct$Iip_unadjusted, method='bonferroni')
agg_citibike_oct$Ii_ad_sig <- 'nonsignificant'
agg_citibike_oct$Ii_ad_sig[which(agg_citibike_oct$Iip_adjusted < 0.05)] <- 'significant'
tm_shape(agg_citibike_oct) + tm_polygons(col='Ii_ad_sig', palette='-RdBu')


# Looking for clusters from local Moran
moranCluster <- function(shape, W, var, alpha=0.05, p.adjust.method='bonferroni')
{
  # Code adapted from https://rpubs.com/Hailstone/346625
  Ii <- localmoran(shape[[var]], W)
  shape$Ii <- Ii[,"Ii"]
  Iip <- p.adjust(Ii[,"Pr(z != E(Ii))"], method=p.adjust.method)
  shape$Iip <- Iip
  shape$sig <- shape$Iip<alpha
  # Scale the data to obtain low and high values
  shape$scaled <- scale(shape[[var]]) # high low values at location i
  shape$lag_scaled <- lag.listw(Wl, shape$scaled) # high low values at neighbours j
  shape$lag_cat <- factor(ifelse(shape$scaled>0 & shape$lag_scaled>0, "HH",
                                 ifelse(shape$scaled>0 & shape$lag_scaled<0, "HL",
                                        ifelse(shape$scaled<0 & shape$lag_scaled<0, "LL",
                                               ifelse(shape$scaled<0 & shape$lag_scaled<0, "LH", "Equivalent")))))
  shape$sig_cluster <- as.character(shape$lag_cat)
  shape$sig_cluster[!shape$sig] <- "Non-sig"
  shape$sig_cluster <- as.factor(shape$sig_cluster)
  results <- data.frame(Ii=shape$Ii, pvalue=shape$Iip, type=shape$lag_cat, sig=shape$sig_cluster)
  
  return(list(results=results))
}

clusters <- moranCluster(agg_citibike_oct, W=Wl, var='total_ride_start_count')$results
agg_citibike_oct$Ii_cluster <- clusters$sig

tm_shape(agg_citibike_oct) + tm_polygons(col='Ii_cluster')


# Testing for spatial autocorrelation in regression errors
octbike.lm <- lm(total_ride_start_count ~ PopU18 + Pop19t64 + Pop65pl + HUnits + Fam + AvgHHSz + GQClgHsg + Shape_Area + num_stations, data=agg_citibike_oct)
# Saving the residuals as a column
agg_citibike_oct$lm.res <- residuals(octbike.lm)
# Plotting the residuals
tm_shape(agg_citibike_oct)+tm_polygons('lm.res', palette='-RdBu', style='quantile')


lm.morantest(octbike.lm, D)


lm.LMtests(octbike.lm, D, test='RLMlag')


lm.LMtests(octbike.lm, D, test='RLMerr')


# Load regression libraries
library(spgwr)
library(spatialreg)

# Spatial Lag Regression
octbike.lag <- lagsarlm(total_ride_start_count ~ PopU18 + Pop19t64 + Pop65pl + HUnits + Fam + AvgHHSz + GQClgHsg + Shape_Area + num_stations, data=agg_citibike_oct, listw=D)


summary(octbike.lag)


library(spgwr)
library(spatialreg)

# 设置 K 折交叉验证的参数
set.seed(123)
k <- 5
n <- nrow(agg_citibike_oct)
folds <- sample(1:k, n, replace = TRUE)

# 初始化存储误差的列表
mse_list <- c()
rmse_list <- c()

# 进行 K 折交叉验证
for (i in 1:k) {
  # 划分训练集和测试集
  train_data <- agg_citibike_oct[folds != i, ]
  test_data <- agg_citibike_oct[folds == i, ]
  
  # 提取训练集的空间权重矩阵
  train_D <- subset(D, folds != i)  # 子集化权重矩阵
  
  # 拟合 Spatial Lag 回归模型（允许孤立点）
  model <- lagsarlm(total_ride_start_count ~ PopU18 + Pop19t64 + Pop65pl + HUnits + 
                      Fam + AvgHHSz + GQClgHsg + Shape_Area + num_stations, 
                    data = train_data, listw = train_D, zero.policy = TRUE)
  
  # 在测试集上进行预测（允许孤立点）
  predicted <- predict(model, newdata = test_data, listw = D, zero.policy = TRUE)
  actual <- test_data$total_ride_start_count
  
  # 计算误差
  mse <- mean((predicted - actual)^2)
  rmse <- sqrt(mse)
  
  # 存储误差
  mse_list <- c(mse_list, mse)
  rmse_list <- c(rmse_list, rmse)
}

# 计算平均误差
mean_mse <- mean(mse_list)
mean_rmse <- mean(rmse_list)

# 输出结果
cat("K 折交叉验证结果：\n")
cat("平均 MSE:", mean_mse, "\n")
cat("平均 RMSE:", mean_rmse, "\n")



# 读取 CT2020.csv 文件
ct2020_jan <- read.csv("CT2020_01.csv", colClasses = c("CT2020" = "character"))
ct2020_jan_vector <- ct2020_jan$CT2020


ct2020_oct_vector <- agg_citibike_oct$CT2020


# 找出 1 月有而 10 月没有的值
jan_not_in_oct <- setdiff(ct2020_jan_vector, ct2020_oct_vector)

# 找出 10 月有而 1 月没有的值
oct_not_in_jan <- setdiff(ct2020_oct_vector, ct2020_jan_vector)

# 打印结果并计数
cat("1 月有而 10 月没有的值 (共", length(jan_not_in_oct), "个)：", jan_not_in_oct, "\n")
cat("10 月有而 1 月没有的值 (共", length(oct_not_in_jan), "个)：", oct_not_in_jan, "\n")



# 打印 1 月和 10 月的 CT2020 总数量
cat("1 月的 CT2020 总数量：", length(ct2020_jan_vector), "\n")
cat("10 月的 CT2020 总数量：", length(ct2020_oct_vector), "\n")


# 提取 CT2020 列并保存为数据框
ct2020_df <- data.frame(CT2020 = agg_citibike_oct$CT2020)

# 保存为 CSV 文件
write.csv(ct2020_df, "CT2020_2019_10.csv", row.names = FALSE)


# 找到 1 月和 10 月的交集
common_values <- intersect(ct2020_jan_vector, ct2020_oct_vector)

# 筛选 agg_citibike_oct 中 CT2020 列属于交集的行
agg_citibike_oct_filtered <- agg_citibike_oct[agg_citibike_oct$CT2020 %in% common_values, ]

# 查看结果
cat("筛选前行数：", nrow(agg_citibike_oct), "\n")
cat("筛选后行数：", nrow(agg_citibike_oct_filtered), "\n")




library(spdep)
library(knitr)
nb <- poly2nb(agg_citibike_oct_filtered)
W <- nb2mat(nb, style='W', zero.policy = TRUE)
colnames(W) <- rownames(W)
NbrL <- dnearneigh(st_centroid(agg_citibike_oct_filtered), 0, 1.6)
# Creating a weights list
Wl <- nb2listw(nb, zero.policy = TRUE)
moran(agg_citibike_oct_filtered$total_ride_start_count, Wl, n=length(Wl$neighbours), S0=Szero(Wl))

# Creating a list of neighbours not including self
D <- nb2listw(NbrL, style='B')
# Creating a list of neighbours, but include self
D_star <- nb2listw(include.self(NbrL), style='B')

G <- globalG.test(agg_citibike_oct_filtered$total_ride_start_count, D)
G <- globalG.test(agg_citibike_oct_filtered$total_ride_start_count, D_star)

# Check if there are any isolated observations (no neighbors) by returning the length (number of neighbours) for each polygon
sapply(NbrL, length)


octbike.lag <- lagsarlm(total_ride_start_count ~ PopU18 + Pop19t64 + Pop65pl + HUnits + Fam + AvgHHSz + GQClgHsg + Shape_Area + num_stations, data=agg_citibike_oct_filtered, listw=D)


summary(octbike.lag)


octbike.err <- errorsarlm(total_ride_start_count ~ PopU18 + Pop19t64 + Pop65pl + HUnits + Fam + AvgHHSz + GQClgHsg + Shape_Area + num_stations, data=agg_citibike_oct_filtered, listw=D)


summary(octbike.err)


summary(octbike.lm)



